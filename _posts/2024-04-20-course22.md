# How course 22 changed my persepctive on AI

I had no idea how easy making image classifiers could be.
But that was before I tried out [fast.ai](https://www.fast.ai/)'s course 22.

Turns out you can just add your own layer of classification weights to an already *highly* advanced *super* powerful pretrained deeplearning network.

And then create my own ridiculously accurate 10 class multiclassification computer vision model.

... with only 2 minutes of training time !

... using nothing but my laptops CPU !

Lets step through the process of how cool of an experience this was.

FIRST I found out how easy it was to scrape images off the web. Ive been interested in webscraping for ages, but never had a go at it. well, course22 prompted me to dive in and i was pleasantly suprised. With just a few lines of code using the DuckDuckGo search engine:

```python
# Specify the folder which we want to keep our image data in.
path = Path('CIFAR10_model')
# We want to compile image data for each classification.
for o in searches:
    # Each classification will have its own folder to store its images.
    dest = (path/o)
    dest.mkdir(exist_ok=True, parents=True)
    # Now we use our search function to download 100 images for each classification.
    download_images(dest, urls=search_images(f'{o} photo'))
    sleep(10)  # Pause between searches to avoid over-loading server
    # Lrger images take more computation so we limit the size of each image downloaded.
    resize_images(path/o, max_size=400, dest=path/o)
```

I had scraped and processed close to one 1000 images straight off the internet within a matter of minutes! watching the folders fill up with images was super satisfying.

but then to train my *super* advanced *amazing* image classifier I had to code this monstrosity...

```python
# Create a vision learner using the ResNet18 architecture pre-trained on ImageNet.
# The learner is adapted for the dataset specified by 'dls' with a new head to classify the dataset's categories.
learn = vision_learner(dls, resnet18, metrics=error_rate)

# Fine tune the model over 2 epochs of training.
learn.fine_tune(2)
```
Yep, thats right. Two lines. and Two minutes of cpu processing.

Of course my images did need to be parsed into a datablock but that was also relatively simple:

```python
# Creates a DataBlock
path = Path('CIFAR10_model')
dls = DataBlock(
    # Specifies the two types of datablocks we need:
    # ImageBlock for input images, and CategoryBlock for target labels.
    blocks=(ImageBlock, CategoryBlock), 

    # Recursively retrieves all image files from the provided path.
    get_items=get_image_files, 

    # Splits the data into its training (80%) and validation (20%) sets using a reproducable 'seed' number.
    splitter=RandomSplitter(valid_pct=0.2, seed=42),

    # Uses the name of the folder to classify each image.
    get_y=parent_label,

    # Squishes (not crops) each image to a size of 192 by 192. Cropping may cut out important features.
    item_tfms=[Resize(192, method='squish')]
).dataloaders(path)  # Create a DataLoader object that can be used to access the data.

# Display a batch of 30 images from the DataLoader.
dls.show_batch(max_n=30)
```

But this introduced me to the amazing concept of fine tuning pretrained AI's - super effective, and super easy.

It managed to get all 10 of my image classifications correct ! normally i have to spend hours tuning hyperparameters to do way less exciting stuff.

(examples)
![image](https://github.com/wallindeniall/wallindeniall.github.io/assets/79976872/ef3ed253-38cf-4a86-9ab2-031ab027c779)


Little did I realise the most fun part was yet to come... using a t-SNE to provide a lower dimensional insight to the models training.
![image](https://github.com/wallindeniall/wallindeniall.github.io/assets/79976872/e9b3693d-3a6e-4d03-8044-5b84a6b9a32e)

I had so much fun regenerating this over and over again theorising on what the model i'd trained was associating with.




